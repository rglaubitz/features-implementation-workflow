# Execute Phase Implementation

**Command:** `/execute [phase-number]`
**Purpose:** Systematic implementation using task-manager structure
**Workflow:** Lean 5-step pattern (Load â†’ Execute â†’ Validate â†’ Track â†’ Next)

---

## Prerequisites

Before running `/execute`:

- âœ… `/breakdown` completed (task-manager/ structure exists)
- âœ… All previous phase dependencies met
- âœ… Development environment ready (services running)

**If task-manager/ not found:** Error - Run `/breakdown IMPLEMENTATION.md [project-name]` first

---

## Workflow Overview

The lean 5-step execution pattern:

```
Step 1: Load Task Context (30 sec)
   â””â”€ Auto-read phase tasks, show checklist

Step 2: Execute Subtasks Interactively (varies)
   â””â”€ Work through subtasks with quality standards

Step 3: Validate Implementation (5-10 min)
   â””â”€ Run tests, verify success criteria (BLOCKING quality gate)

Step 4: Track Progress (10 sec)
   â””â”€ Auto-update task-manager/ READMEs

Step 5: Next Action (instant)
   â””â”€ Show next task, recommend compacts
```

**Total overhead per phase:** ~10 minutes (vs 30+ minutes in legacy workflow)

---

## Step 1: Load Task Context ðŸ“‚

**Auto-detect task-manager/ structure and load phase tasks.**

### Detection

Check for `task-manager/` directory in current project:

```bash
if [ -d "task-manager/" ]; then
    echo "âœ… Task Manager structure detected"
    TASK_MANAGER_MODE=true
else
    echo "âŒ No task-manager/ found"
    echo "   Run: /breakdown IMPLEMENTATION.md [project-name]"
    exit 1
fi
```

### Load Phase Tasks

**Read these files automatically:**

1. **Master README** - `task-manager/README.md`
   - Overall project progress
   - All phases with completion status

2. **Phase Overview** - `task-manager/phase-{N}-*/README.md`
   - Current phase summary
   - All tasks for this phase
   - Phase dependencies

3. **Task Files** - `task-manager/phase-{N}-*/task-{N}.{M}-*.md`
   - Detailed task breakdown
   - Subtasks (2-4 hour actionable chunks)
   - Dependencies (what must be complete first)
   - Success criteria (measurable outcomes)
   - Research references (ADRs, docs with line numbers)
   - Test specifications (exact tests to create)

### Display Context

**Announce loaded context:**

```
ðŸ“‚ TASK CONTEXT LOADED

Phase {N}: {Phase Name}
Duration: {X} weeks
Status: {Current status}

Tasks for this phase:
â”œâ”€ Task {N}.1: {Name} ({Duration}, {Y} tests)
â”‚  â”œâ”€ Subtask {N}.1.1: {Name} (4 hours)
â”‚  â”œâ”€ Subtask {N}.1.2: {Name} (6 hours)
â”‚  â”œâ”€ Subtask {N}.1.3: {Name} (6 hours)
â”‚  â””â”€ Subtask {N}.1.4: {Name} (4 hours)
â”‚
â”œâ”€ Task {N}.2: {Name} ({Duration}, {Z} tests)
â”‚  â”œâ”€ Subtask {N}.2.1: {Name} (4 hours)
â”‚  â””â”€ ...
â”‚
â””â”€ ... (all tasks for phase)

Phase Totals:
  - Tasks: {X}
  - Subtasks: {Y}
  - Tests: {Z}
  - Estimated Duration: {N} weeks

Research References:
  - ADR-00{X}: {Title} (referenced in Task {N}.{M})
  - research/documentation/{topic}.md (lines {X}-{Y})

Dependencies Verified:
  âœ“ {Dependency 1} (Phase {N-1} complete)
  âœ“ {Dependency 2} ({Service} running)

âœ“ All task files loaded
âœ“ Research references extracted
âœ“ Test specifications identified
âœ“ Ready to implement
```

### Quality Gate

**Verify before proceeding:**

- âœ… task-manager/ structure exists and is valid
- âœ… All phase task files are readable
- âœ… Dependencies from previous phases are met
- âœ… Success criteria are clearly defined
- âœ… Research references are accessible

**NO REDUNDANT PLANNING** - Just load and display what `/breakdown` already documented.

**Time:** ~30 seconds (automated file reading)

---

## Step 2: Execute Subtasks Interactively ðŸ’»

**Work through subtasks systematically with quality standards.**

### Task Execution Loop

**For each task in the phase:**

#### Display Current Task

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Task {N}.{M}: {Task Name}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Duration: {X} hours
Tests: {Y} specifications
Status: â¬œ Not Started

Dependencies:
  {List dependencies or "None - ready to start"}

Success Criteria:
  1. {Criterion 1} (measurable outcome)
  2. {Criterion 2} (measurable outcome)
  3. {Criterion 3} (measurable outcome)
  ...

Research References:
  - {ADR or doc} (lines {X}-{Y}) - {Why relevant}
  - {ADR or doc} (lines {A}-{B}) - {Why relevant}

Subtasks:
  â¬œ {N}.{M}.1: {Name} (4 hours)
  â¬œ {N}.{M}.2: {Name} (6 hours)
  â¬œ {N}.{M}.3: {Name} (6 hours)
  â¬œ {N}.{M}.4: {Name} (4 hours)
```

### Subtask Execution

**For each subtask in the task:**

#### 1. Display Subtask Details

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Subtask {N}.{M}.{S}: {Name}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Duration: {X} hours
Status: â¬œ Not Started

Implementation Steps:
  {Copy steps directly from task file}

Files to Create/Modify:
  {List from task file}

Code Examples:
  {Reference to IMPLEMENTATION.md sections via task file}

Validation Commands:
  {Commands from task file to verify this subtask}
```

#### 2. Implement the Code

**Quality Standards (Applied Automatically):**

**Code Quality:**
- âœ… Type hints everywhere (`def func(x: int) -> str:`)
- âœ… Google-style docstrings for all classes/functions
- âœ… Async/await where appropriate
- âœ… Structured logging (`logger.info()`, not `print()`)
- âœ… Proper error handling (specific exceptions, try/except)
- âœ… No TODO/FIXME in production code

**Code Pattern:**
```python
"""Module-level docstring explaining purpose.

Author: Apex Infrastructure Team
Created: {YYYY-MM-DD}
"""

import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)


class ComponentName:
    """Component description.

    This component handles {what it does}.

    Args:
        param1: Description.
        param2: Description.

    Examples:
        >>> component = ComponentName()
        >>> result = await component.method()
    """

    def __init__(self, param1: str, param2: Optional[int] = None):
        """Initialize component."""
        self.param1 = param1
        self.param2 = param2
        logger.info(f"Initialized {self.__class__.__name__}")

    async def method(self) -> Dict[str, Any]:
        """Method description.

        Returns:
            Dictionary with results.

        Raises:
            ValueError: If validation fails.
        """
        try:
            # Implementation
            result = await self._internal_method()
            logger.info(f"Method completed successfully")
            return result
        except Exception as e:
            logger.error(f"Method failed: {e}")
            raise
```

**File Organization:**
- âœ… Modular design (200-500 lines per file)
- âœ… Clear imports and dependencies
- âœ… Logical file structure (group related functionality)

#### 3. Announce Progress

```
ðŸ“ Implementing Subtask {N}.{M}.{S}...

Creating/Modifying:
  - {File 1} ({NEW/MODIFY}) - {Purpose}
  - {File 2} ({NEW/MODIFY}) - {Purpose}

Lines: ~{Estimated lines}
```

#### 4. Validate Subtask

**Run validation commands from task file:**

```bash
# Example validation commands
alembic upgrade head                    # Database migration
python -c "from module import Class"    # Import verification
curl http://localhost:8000/endpoint     # API endpoint check
```

**Show results:**

```
Validation Results:
  âœ“ {Validation 1} passed
  âœ“ {Validation 2} passed
  âœ“ {Validation 3} passed
```

#### 5. Mark Subtask Complete

```
âœ… Subtask {N}.{M}.{S} Complete

Delivered:
  âœ“ {File 1} created ({X} lines)
  âœ“ {File 2} updated (+{Y} lines)
  âœ“ All validations passed

Time: {Actual time spent}
```

### Task Progress Tracking

**Show continuous progress:**

```
Task {N}.{M} Progress:
  â”œâ”€ Subtasks: {S}/{TOTAL} complete ({XX}%)
  â”œâ”€ Estimated remaining: {X} hours
  â””â”€ Status: {On Track / Ahead / Behind}
```

**When all subtasks complete, proceed to Step 3 (Validate Implementation).**

**NO REDUNDANT DISCUSSION** - Just execute what's documented in subtask steps.

**Time:** Varies by subtask complexity (actual implementation work)

---

## Step 3: Validate Implementation âœ…

**Run tests and verify success criteria - THIS IS A BLOCKING QUALITY GATE.**

### Automatic Test Generation

**Generate tests proactively (WITHOUT being asked):**

After implementing each task, IMMEDIATELY create comprehensive tests.

#### Test Structure

```python
# File: tests/unit/test_{component}.py (NEW)

"""Unit tests for {component}.

Tests verify:
- Core functionality
- Edge cases
- Error handling
- Integration points

Test Specifications: TESTING.md lines {X}-{Y}

Author: Apex Infrastructure Team
Created: {YYYY-MM-DD}
"""

import pytest
from unittest.mock import Mock, AsyncMock, patch

from apex_memory.{module} import ComponentName


@pytest.fixture
def component():
    """Fixture providing test component instance."""
    return ComponentName(param1="test-value")


@pytest.mark.asyncio
async def test_core_functionality(component):
    """Test primary use case.

    Validates: {Success criterion from task file}
    """
    result = await component.method()

    assert result is not None
    assert result["status"] == "success"


@pytest.mark.asyncio
async def test_edge_case_empty_input(component):
    """Test handling of empty input.

    Validates: Edge case from TESTING.md line {X}
    """
    result = await component.method_with_input("")

    assert result["status"] == "skipped"


@pytest.mark.asyncio
async def test_error_handling(component):
    """Test error handling for invalid input.

    Validates: Error handling requirement
    """
    with pytest.raises(ValueError):
        await component.method_with_validation("invalid")


@pytest.mark.asyncio
async def test_integration_with_external_service(component):
    """Test integration with external service.

    Validates: Integration point from task dependencies
    """
    with patch("apex_memory.external.service_call") as mock_service:
        mock_service.return_value = {"data": "test"}

        result = await component.call_external_service()

        assert result["data"] == "test"
        mock_service.assert_called_once()
```

**Announce test creation:**

```
âœ¨ Generating tests for Task {N}.{M}...

Test File: tests/unit/test_{component}.py (NEW)
Test Count: {Y} tests
Scenarios:
  - Core functionality ({X} tests)
  - Edge cases ({Y} tests)
  - Error handling ({Z} tests)
  - Integration points ({A} tests)

Coverage Target: 80%+
```

### Run Test Suite

**Execute tests for this task:**

```bash
# Run tests
pytest tests/unit/test_{component}.py -v

# Check coverage
pytest tests/unit/test_{component}.py \
  --cov=apex_memory.{module} \
  --cov-report=term \
  --cov-report=html
```

**Display results:**

```
Running tests for Task {N}.{M}...

Test Results:
  âœ“ test_core_functionality PASSED
  âœ“ test_edge_case_empty_input PASSED
  âœ“ test_error_handling PASSED
  âœ“ test_integration_with_external_service PASSED
  ... (all tests)

Summary:
  âœ“ {Y}/{Y} tests passing (100%)
  âœ“ Coverage: {X}% (target: 80%+)
  âœ“ No failures or errors
```

### Verify Success Criteria

**Check each criterion from task file:**

```
Verifying Task {N}.{M} success criteria:

From task file:
  1. {Criterion 1}
     âœ“ Verified: {How verified}

  2. {Criterion 2}
     âœ“ Verified: {How verified}

  3. {Criterion 3}
     âœ“ Verified: {How verified}

  ... (all criteria)

All success criteria met: âœ…
```

### Quality Gate (BLOCKING)

**This gate BLOCKS progression if not met.**

#### If Tests Fail or Criteria Not Met:

```
âš ï¸  QUALITY GATE FAILED

Cannot proceed to next task until issues resolved.

Issues Found:
  âŒ test_{name} FAILED
     Error: {Error message}
     Fix required: {Suggested fix}

  âŒ Success criterion "{Criterion}" NOT MET
     Expected: {Expected state}
     Actual: {Actual state}
     Fix required: {Suggested fix}

Actions Required:
  1. Fix failing tests
  2. Verify all success criteria
  3. Re-run validation (Step 3)

Do NOT proceed until quality gate passes.
```

**User must fix issues and validation must pass before continuing.**

#### If All Pass:

```
âœ… QUALITY GATE PASSED

Task {N}.{M}: {Task Name}

Validation Results:
  âœ“ All success criteria met ({X}/{X})
  âœ“ All tests passing ({Y}/{Y})
  âœ“ Code coverage: {Z}% (â‰¥80% target)
  âœ“ No errors or warnings

Implementation Quality:
  âœ“ Type hints complete
  âœ“ Docstrings complete
  âœ“ Error handling implemented
  âœ“ Logging structured
  âœ“ No TODO/FIXME in production code

Ready to mark Task {N}.{M} complete and update progress.

Proceeding to Step 4...
```

**ENFORCES QUALITY** - Cannot skip failing tests or incomplete success criteria.

**Time:** 5-10 minutes per task (automated testing + verification)

---

## Step 4: Track Progress ðŸ“Š

**Automatically update task-manager/ structure with completion status.**

### Update Task File

**File:** `task-manager/phase-{N}-*/task-{N}.{M}-*.md`

**Update header:**
```markdown
**Status:** âœ… Complete
**Completed:** {YYYY-MM-DD}
**Actual Duration:** {X} hours (estimated: {Y} hours)
```

**Update progress tracking section:**
```markdown
## Progress Tracking

**Subtasks:** 4/4 complete (100%)

- [x] Subtask {N}.{M}.1: {Name} âœ… ({Completion date})
- [x] Subtask {N}.{M}.2: {Name} âœ… ({Completion date})
- [x] Subtask {N}.{M}.3: {Name} âœ… ({Completion date})
- [x] Subtask {N}.{M}.4: {Name} âœ… ({Completion date})

**Tests:** {Y}/{Y} passing (100%)
**Success Criteria:** {X}/{X} met (100%)
```

### Update Phase README

**File:** `task-manager/phase-{N}-*/README.md`

**Update task table:**
```markdown
| Task | Name | Status | Duration | Tests | Subtasks |
|------|------|--------|----------|-------|----------|
| {N}.1 | {Name} | âœ… | 2 days | 10/10 | 4/4 |
| {N}.2 | {Name} | â¬œ | 1 day | 0/6 | 0/4 |
| {N}.3 | {Name} | â¬œ | 1 day | 0/4 | 0/4 |
```

**Update totals:**
```markdown
**Totals:**
- Tasks: 1/4 complete (25%)
- Subtasks: 4/16 complete (25%)
- Tests: 10/42 passing (24%)
```

### Update Master README

**File:** `task-manager/README.md`

**Update progress table:**
```markdown
| Phase | Name | Tasks | Subtasks | Tests | Status | Progress |
|-------|------|-------|----------|-------|--------|----------|
| {N} | {Phase Name} | 1/4 | 4/16 | 10/42 | ðŸ”„ | 25% |
```

**Update overall progress:**
```markdown
**Overall Progress:** {X}/23 tasks ({Y}%) | {A}/89 subtasks ({B}%)
```

### Display Update Summary

```
ðŸ“Š PROGRESS UPDATED

Task {N}.{M} Complete:
  âœ“ 4/4 subtasks done
  âœ“ {Y}/{Y} tests passing (100%)
  âœ“ All success criteria met
  âœ“ Completed: {YYYY-MM-DD}
  âœ“ Duration: {X} hours (estimated: {Y} hours)

Files Updated:
  âœ“ task-manager/phase-{N}-*/task-{N}.{M}-*.md
  âœ“ task-manager/phase-{N}-*/README.md
  âœ“ task-manager/README.md

Phase {N} Progress:
  â”œâ”€ Tasks: {X}/{TOTAL} complete ({Y}%)
  â”œâ”€ Subtasks: {A}/{TOTAL} complete ({B}%)
  â””â”€ Tests: {C}/{TOTAL} passing ({D}%)

Overall Project Progress:
  â”œâ”€ Tasks: {E}/23 complete ({F}%)
  â”œâ”€ Subtasks: {G}/89 complete ({H}%)
  â””â”€ Tests: {I}/107 passing ({J}%)

Estimated Remaining: {X} hours this phase, {Y} hours total
```

**FULLY AUTOMATED** - No manual README editing required.

**Time:** ~10 seconds (automated file updates)

---

## Step 5: Next Action ðŸŽ¯

**Provide clear guidance on what to do next.**

### Determine Next Action

**Three possible states:**

1. **More tasks in current phase** â†’ Continue to next task
2. **Phase complete** â†’ Recommend context compact
3. **Project complete** â†’ Celebrate and prepare deployment

### State 1: More Tasks in Phase

**If tasks remaining in current phase:**

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NEXT TASK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Task {N}.{M+1}: {Task Name}

Duration: {X} hours
Tests: {Y} tests to create
Dependencies:
  âœ“ Task {N}.{M} (Complete)
  {Other dependencies if any}

Subtasks:
  â¬œ {N}.{M+1}.1: {Name} (4 hours)
  â¬œ {N}.{M+1}.2: {Name} (6 hours)
  â¬œ {N}.{M+1}.3: {Name} (3 hours)
  â¬œ {N}.{M+1}.4: {Name} (2 hours)

Phase {N} Progress: {X}/{TOTAL} tasks ({Y}%)
Estimated Remaining: {Z} hours

Ready to continue? Proceeding to Step 2 for next task...
```

**Auto-proceed to Step 2 (Execute Subtasks) for next task.**

### State 2: Phase Complete

**If all tasks in phase are done:**

```
ðŸŽ‰ PHASE {N} COMPLETE!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PHASE COMPLETION SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Phase {N}: {Phase Name}
Duration: {X} weeks (estimated: {Y} weeks)
Status: âœ… COMPLETE

Tasks Completed:
  âœ… Task {N}.1: {Name} ({Duration}, {Tests} tests)
  âœ… Task {N}.2: {Name} ({Duration}, {Tests} tests)
  âœ… Task {N}.3: {Name} ({Duration}, {Tests} tests)
  âœ… Task {N}.4: {Name} ({Duration}, {Tests} tests)

Deliverables:
  âœ“ {X} implementation files created/modified
  âœ“ {Y} lines of code written
  âœ“ {Z} tests created (100% passing)
  âœ“ {A} research references used
  âœ“ All success criteria met

Quality Metrics:
  âœ“ Test coverage: {X}% (â‰¥80% target)
  âœ“ Code quality: All standards met
  âœ“ Documentation: 100% complete
  âœ“ No TODO/FIXME in production code

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸  RECOMMENDED: Context Compact

Why compact now:
  - Phase {N} complete ({X} tasks, {Y} subtasks)
  - ~{Z} hours of implementation discussion
  - Next phase: {A} tasks, ~{B} hours of new work
  - Estimated conversation size: {C}k tokens

What gets preserved:
  âœ“ All code files created
  âœ“ All tests and validation results
  âœ“ Progress in task-manager/ (all READMEs updated)
  âœ“ Phase completion status
  âœ“ Critical architectural decisions

What gets summarized:
  - Step-by-step implementation details
  - Code generation discussions
  - Test creation iterations
  - Debugging sessions

Resume Command After Compact:
  /execute {N+1}

Options:
  1. /compact (RECOMMENDED - cleaner context for next phase)
  2. /execute {N+1} (continue without compact)
  3. Take a break (checkpoint saved, can resume anytime)

Current state saved in task-manager/ - safe to compact or pause.
```

### State 3: Project Complete

**If all phases are done:**

```
ðŸ† PROJECT COMPLETE! ðŸ†

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{PROJECT NAME} - IMPLEMENTATION COMPLETE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

All {TOTAL} phases completed successfully!

Phase Summary:
  âœ… Phase 1: {Name} ({X} tasks, {Y} tests)
  âœ… Phase 2: {Name} ({A} tasks, {B} tests)
  âœ… Phase 3: {Name} ({C} tasks, {D} tests)
  ... (all phases)

Final Statistics:
  âœ“ Tasks: {X}/{X} complete (100%)
  âœ“ Subtasks: {Y}/{Y} complete (100%)
  âœ“ Tests: {Z}/{Z} passing (100%)
  âœ“ Files: {A} implementation files
  âœ“ Lines: ~{B} lines of code
  âœ“ Duration: {C} weeks (estimated: {D} weeks)

Quality Achievements:
  âœ“ 100% test pass rate
  âœ“ {X}% code coverage (â‰¥80% target)
  âœ“ Zero TODO/FIXME in production code
  âœ“ Complete documentation
  âœ“ All examples working

Next Steps:
  1. Review TESTING.md - Run full test suite
  2. Review DEPLOYMENT-GUIDE.md - Prepare deployment
  3. Run production readiness checklist
  4. Deploy to staging environment
  5. User acceptance testing
  6. Production deployment

Congratulations! Ready for deployment. ðŸš€
```

### Smart Compact Recommendations

**Automatically suggest context compact based on:**

**Triggers:**
- âœ… Each phase complete (natural break point)
- âœ… Before starting tasks >16 hours (multi-day work)
- âœ… When conversation >150k tokens (approaching limit)

**Compact Timing Example:**
```
ðŸ’¡ Smart Compact Recommendation

Compact suggested because:
  - Phase {N} complete (natural checkpoint)
  - {X} hours of detailed implementation work
  - Conversation size: ~{Y}k tokens
  - Next phase: New features, different focus area

Benefits of compacting now:
  âœ“ Cleaner context for Phase {N+1}
  âœ“ Faster Claude responses
  âœ“ Better focus on new work
  âœ“ All progress preserved in task-manager/

Checkpoint saved: phase-{N}-complete
Resume command: /execute {N+1}

Safe to compact - all state preserved in files.
```

### Create Checkpoint

**Before any potential compact or break:**

```
Checkpoint Saved: phase-{N}-complete

Current State:
  - Phase {N}: âœ… Complete ({X}/{X} tasks)
  - Overall: {Y}/23 tasks ({Z}%)
  - Next: Phase {N+1} ({A} tasks, ~{B} hours)

Resume Command:
  /execute {N+1}

All progress saved in:
  âœ“ task-manager/README.md (master progress)
  âœ“ task-manager/phase-{N}-*/README.md (phase complete)
  âœ“ task-manager/phase-{N}-*/task-*.md (all tasks)

Safe to:
  - Take a break
  - Compact context
  - Switch projects

Can resume anytime with /execute {N+1}
```

**ALWAYS ORIENTED** - Developer always knows what's next, when to compact, how to resume.

**Time:** Instant (guidance display only)

---

## Quick Reference

### Command Usage

```bash
# Auto-detect next phase
/execute

# Execute specific phase
/execute 1        # Phase 1
/execute 2        # Phase 2
/execute 3        # Phase 3
```

### Prerequisites Checklist

Before running `/execute [phase]`:

```
â˜‘ /breakdown completed (task-manager/ exists)
â˜‘ Previous phases complete (check dependencies)
â˜‘ Development environment ready
  â˜‘ Services running (databases, APIs, etc.)
  â˜‘ Dependencies installed
  â˜‘ Environment variables configured
â˜‘ Tests from previous phases still passing
```

### The 5-Step Workflow

```
1. LOAD (30 sec)
   â””â”€ Read task files â†’ Show checklist

2. EXECUTE (varies)
   â””â”€ Implement subtasks â†’ Quality code

3. VALIDATE (5-10 min)
   â””â”€ Generate tests â†’ Verify criteria â†’ BLOCKING GATE

4. TRACK (10 sec)
   â””â”€ Update READMEs â†’ Show progress

5. NEXT (instant)
   â””â”€ Show next task â†’ Recommend compact â†’ Save checkpoint
```

### Quality Standards

**Code Quality (Automatically Applied):**
- âœ… Type hints everywhere
- âœ… Google-style docstrings
- âœ… Async/await where appropriate
- âœ… Structured logging (no print statements)
- âœ… Proper error handling (specific exceptions)
- âœ… No TODO/FIXME in production code

**Testing Standards:**
- âœ… Tests generated proactively (without asking)
- âœ… Unit tests (component isolation)
- âœ… Integration tests (component interaction)
- âœ… Edge cases (boundary conditions)
- âœ… Error tests (exception handling)
- âœ… Coverage â‰¥80% target
- âœ… 100% test pass rate (blocking gate)

**Progress Tracking:**
- âœ… Fully automated README updates
- âœ… Real-time progress metrics
- âœ… Estimated time remaining
- âœ… Checkpoint saves for safe resumption

### Time Estimates

**Per Phase:**
- Setup: ~30 seconds (Step 1)
- Implementation: Varies (Step 2 - actual coding)
- Validation: ~5-10 minutes per task (Step 3)
- Progress tracking: ~10 seconds (Step 4)
- Next action: Instant (Step 5)

**Total Overhead:** ~10 minutes per phase (vs 30+ minutes in legacy workflow)

### Success Metrics

**What This Workflow Delivers:**
- âœ… Zero redundant planning (trusts /breakdown)
- âœ… Quality enforced (cannot skip failing tests)
- âœ… Progress automated (no manual README updates)
- âœ… Always oriented (clear next steps)
- âœ… Context efficient (strategic compact reminders)
- âœ… Fast execution (30 sec setup vs 15-30 min)

---

## Validation Checkpoints

**Step 1 (Load):**
- [ ] task-manager/ structure detected
- [ ] All task files loaded successfully
- [ ] Dependencies verified
- [ ] Context displayed clearly

**Step 2 (Execute):**
- [ ] Subtasks executed in order
- [ ] Quality standards applied
- [ ] Code follows patterns
- [ ] Validation commands pass

**Step 3 (Validate):**
- [ ] Tests generated proactively
- [ ] All tests passing (100%)
- [ ] Success criteria met
- [ ] Quality gate enforced

**Step 4 (Track):**
- [ ] Task file updated (status, completion date)
- [ ] Phase README updated (task table, totals)
- [ ] Master README updated (progress, overall stats)
- [ ] Progress displayed accurately

**Step 5 (Next):**
- [ ] Next action clear
- [ ] Compact recommended at right time
- [ ] Checkpoint saved
- [ ] Resume command provided

---

**This workflow implements the lean execution pattern that complements /breakdown with zero redundancy and maximum efficiency.**
