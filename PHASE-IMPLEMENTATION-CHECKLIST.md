# Phase Implementation Checklist

**Detailed checklist for implementing each phase (Phases 2-5)**

Use this checklist for every implementation phase to ensure nothing is missed.

---

## Pre-Phase Checklist

Before starting ANY phase:

```
‚òê Previous phase is 100% complete
‚òê Previous phase context has been compacted
‚òê IMPLEMENTATION-GUIDE.md section for this phase is reviewed
‚òê All required research documents are available
‚òê Dependencies from previous phases are verified
```

---

## Step 1: Enter Plan Mode üõë

```
‚òê User initiates phase: "Let's start Phase X"
‚òê Claude enters plan mode (no tool execution)
‚òê Plan mode confirmed active
```

**Expected output:**
```
Claude: "Entering plan mode for Phase X. Let me review the requirements..."
```

---

## Step 2: Discuss Phase Requirements üí¨

```
‚òê Review implementation guide for this phase
‚òê List all components to be implemented
‚òê Identify dependencies on other components
‚òê Check for unclear specifications
‚òê Identify potential challenges
```

**Discussion prompts:**
- "For Phase X, we need to implement: [list]"
- "Dependencies: [list]"
- "Questions: [list]"
- "Do we need additional research for [topic]?"

**Example discussion:**
```
Claude: "For Phase 2 (Intelligent Routing), we need:
         1. Adaptive weights using contextual bandit
         2. GraphRAG hybrid search (Neo4j vector index)
         3. Semantic caching (similarity threshold)

         Dependencies:
         - Phase 1 semantic classifier must be complete
         - Neo4j 5.11+ for vector index support
         - Redis for cache storage

         Questions:
         - Do we need to verify Neo4j version?
         - Should we research cache memory sizing?
         - Do we have example training data for bandit?"
```

---

## Step 3: Identify Research Gaps üìö

```
‚òê Check if all framework documentation is available
‚òê Verify version numbers are known
‚òê Check if code examples exist
‚òê Identify missing API documentation
‚òê Note any unclear best practices
```

**If gaps found:**
```
‚òê Use Exa AI to find official documentation
‚òê Use GitHub API to verify versions
‚òê Search for code examples (1.5k+ stars)
‚òê Create new research document if needed
‚òê Save research to research/documentation/
```

**Quality gate:**
- Only Tier 1-2 sources (official docs, high-star repos)
- No blog posts or tutorials
- All sources dated and cited

---

## Step 4: Exit Plan Mode ‚ñ∂Ô∏è

```
‚òê All questions answered
‚òê All research gaps filled
‚òê Implementation approach agreed upon
‚òê User gives go-ahead signal
‚òê Claude exits plan mode
```

**User signals:**
- "Let's go"
- "Proceed"
- "Execute"
- "Start implementation"

**Claude confirms:**
```
Claude: "Plan complete. Proceeding with Phase X implementation."
```

---

## Step 5: Write Implementation Code üíª

```
‚òê Create new files (3-5 typical per phase)
‚òê Use researched versions and patterns
‚òê Add type hints (Python)
‚òê Write Google-style docstrings
‚òê Use async/await where appropriate
‚òê Add proper error handling
‚òê Use structured logging (no print statements)
‚òê Add circuit breakers for external calls
‚òê Include usage examples in docstrings
```

**Code quality checklist:**
```python
# ‚úÖ Good Example
"""Module for semantic intent classification.

Uses semantic-router 0.1.11 for embedding-based routing.
Replaces brittle keyword matching with ML-based classification.
"""

import logging
from typing import Optional
from semantic_router import Route, SemanticRouter

logger = logging.getLogger(__name__)

class SemanticIntentClassifier:
    """Semantic intent classification using embeddings."""

    def __init__(self, openai_api_key: str):
        """Initialize semantic router.

        Args:
            openai_api_key: OpenAI API key for embeddings
        """
        self.router = SemanticRouter(...)
        logger.info("Semantic router initialized")

    async def classify(self, query: str) -> Optional[str]:
        """Classify query intent.

        Args:
            query: Natural language query

        Returns:
            Intent name or None for out-of-scope
        """
        try:
            route = await self.router(query)
            return route.name if route else None
        except Exception as e:
            logger.error(f"Classification failed: {e}")
            return None
```

**File naming conventions:**
```
src/apex_memory/query_router/
‚îú‚îÄ‚îÄ semantic_classifier.py        # NEW for Phase 1
‚îú‚îÄ‚îÄ query_rewriter.py             # NEW for Phase 1
‚îú‚îÄ‚îÄ analytics.py                  # NEW for Phase 1
‚îú‚îÄ‚îÄ adaptive_weights.py           # NEW for Phase 2
‚îú‚îÄ‚îÄ graphiti_search.py            # NEW for Phase 2
‚îî‚îÄ‚îÄ semantic_cache.py             # NEW for Phase 2
```

---

## Step 6: Generate Tests Proactively ‚ú®

**CRITICAL:** Generate tests WITHOUT user asking!

```
‚òê After coding, automatically start creating tests
‚òê Create tests/unit/test_[component].py
‚òê Create tests/integration/test_[component]_integration.py
‚òê Write 15-30 tests per phase
‚òê Cover happy path cases
‚òê Cover edge cases
‚òê Cover error conditions
‚òê Use pytest fixtures
‚òê Add clear test descriptions
‚òê Make tests runnable
```

**Test structure template:**
```python
# tests/unit/test_semantic_classifier.py

import pytest
from src.apex_memory.query_router.semantic_classifier import SemanticIntentClassifier

@pytest.fixture
def classifier():
    """Create classifier instance for testing."""
    return SemanticIntentClassifier(api_key="test-key")

class TestSemanticClassifier:
    """Test suite for semantic classification."""

    def test_graph_query_classification(self, classifier):
        """Test graph queries are correctly classified."""
        queries = [
            "what is connected to ACME Corp",
            "show relationships between X and Y",
            "network of connections for customer"
        ]
        for query in queries:
            result = classifier.classify(query)
            assert result == "graph", f"Failed for: {query}"

    def test_temporal_query_classification(self, classifier):
        """Test temporal queries are correctly classified."""
        queries = [
            "how did this change over time",
            "payment trends last 6 months",
            "evolution of customer behavior"
        ]
        for query in queries:
            result = classifier.classify(query)
            assert result == "temporal", f"Failed for: {query}"

    def test_out_of_scope_detection(self, classifier):
        """Test out-of-scope queries return None."""
        queries = [
            "what is the weather today",
            "how to cook pasta",
            "latest sports scores"
        ]
        for query in queries:
            result = classifier.classify(query)
            assert result is None, f"Should be OOS: {query}"

    def test_error_handling(self, classifier):
        """Test error handling for invalid inputs."""
        # Empty query
        assert classifier.classify("") is None

        # Very long query
        long_query = "test " * 10000
        result = classifier.classify(long_query)
        assert result is not None or result is None  # Should not crash

    @pytest.mark.asyncio
    async def test_async_classification(self, classifier):
        """Test async classification works correctly."""
        result = await classifier.classify("what is connected to ACME")
        assert result == "graph"
```

**Test coverage targets:**
- Unit tests: 80%+ coverage
- Integration tests: Key workflows covered
- Edge cases: All boundary conditions
- Error cases: All exception paths

---

## Step 7: Create Working Examples üìù

```
‚òê Create example configuration files
‚òê Create setup scripts
‚òê Create router configurations (phase1.py, phase2.py, etc.)
‚òê Create integration examples
‚òê Ensure all examples are copy-paste ready
‚òê Remove all TODOs and placeholders
‚òê Add comments explaining key decisions
‚òê Test examples actually work
```

**Example file structure:**
```python
# upgrades/[feature]/examples/router_config_phase2.py

"""
Query Router Configuration - Phase 2 (Intelligent Routing)

This configuration enables:
- Adaptive score weighting with contextual bandit
- GraphRAG hybrid search
- Semantic caching

Requirements:
- Neo4j 5.11+ (for vector index)
- Redis (for semantic cache)
- Phase 1 components (semantic classifier, query rewriter)
"""

import os
from apex_memory.query_router.router import QueryRouter

async def create_phase2_router():
    """Create router with Phase 2 features enabled."""

    router = QueryRouter(
        # Phase 1: Foundation (ENABLED)
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
        enable_semantic_classification=True,
        enable_query_rewriting=True,
        enable_analytics=True,

        # Phase 2: Intelligent Routing (NEW - ENABLED)
        enable_adaptive_routing=True,      # ‚Üê NEW
        enable_graphrag=True,              # ‚Üê NEW
        enable_semantic_cache=True,        # ‚Üê NEW
        bandit_alpha=0.5,                  # Exploration parameter
        cache_similarity_threshold=0.95,   # Semantic cache threshold

        # Database connections
        neo4j_uri=os.getenv("NEO4J_URI"),
        postgres_dsn=os.getenv("POSTGRES_DSN"),
        redis_host=os.getenv("REDIS_HOST"),
    )

    await router.initialize()

    print("‚úÖ Phase 2 router initialized!")
    print("   - Adaptive routing: ENABLED")
    print("   - GraphRAG: ENABLED")
    print("   - Semantic cache: ENABLED")

    return router


if __name__ == "__main__":
    import asyncio
    router = asyncio.run(create_phase2_router())

    # Example query
    result = asyncio.run(router.query("what equipment is connected to ACME Corp"))
    print(f"\nQuery result: {len(result)} documents found")
```

**Example naming conventions:**
```
upgrades/[feature]/examples/
‚îú‚îÄ‚îÄ router_config_phase1.py       # Foundation only
‚îú‚îÄ‚îÄ router_config_phase2.py       # Phase 1 + Phase 2
‚îú‚îÄ‚îÄ router_config_phase3.py       # Phases 1-3
‚îî‚îÄ‚îÄ router_config_phase4.py       # All phases (full power)
```

---

## Step 8: Update Documentation üìÑ

```
‚òê Create or update README_PHASEX.md
‚òê Update CHANGELOG.md with phase section
‚òê Update IMPLEMENTATION_STATE.md with completion status
‚òê Update main README.md if needed
‚òê Add cross-references between docs
‚òê Verify all links work
```

**README_PHASEX.md template:**
```markdown
# Phase X: [Phase Name]

**Status:** ‚úÖ COMPLETE
**Timeline:** Week X-Y
**Files:** [count] implementation, [count] tests, [count] examples

---

## Overview

[Brief description of what this phase accomplishes]

---

## Components Implemented

### 1. [Component Name]

**File:** `src/apex_memory/[path]/[file].py`
**Lines:** ~[count]
**Purpose:** [Brief description]

**Key features:**
- Feature 1
- Feature 2
- Feature 3

**Usage example:**
```python
from apex_memory.[path] import [Component]

# Example usage
component = Component(...)
result = component.method(...)
```

### 2. [Component Name]
... (repeat for each component)

---

## Tests

**Total:** [count] tests
**Coverage:** [percentage]%

**Test files:**
- `tests/unit/test_[component].py` ([count] tests)
- `tests/integration/test_[component]_integration.py` ([count] tests)

**Run tests:**
```bash
pytest tests/unit/test_[component].py -v
```

---

## Examples

**Created:**
- `examples/router_config_phase[X].py`
- `examples/[other_example].py`

**Run example:**
```bash
python examples/router_config_phase[X].py
```

---

## Configuration

**New parameters:**
```python
router = QueryRouter(
    enable_[feature]=True,  # NEW
    [param]=[value],        # NEW
)
```

---

## Performance Metrics

**Expected improvements:**
- [Metric 1]: [baseline] ‚Üí [target]
- [Metric 2]: [baseline] ‚Üí [target]

---

## Next Steps

Phase [X+1]: [Next phase name]
```

**CHANGELOG.md update:**
```markdown
## Phase X: [Phase Name] (Week X-Y)

### Added
- ‚úÖ [Component 1]: [Description]
- ‚úÖ [Component 2]: [Description]
- ‚úÖ [Component 3]: [Description]

### Tests
- ‚úÖ [count] unit tests
- ‚úÖ [count] integration tests
- ‚úÖ [percentage]% code coverage

### Examples
- ‚úÖ router_config_phase[X].py
- ‚úÖ [other examples]

### Performance
- [Metric]: [improvement]

### Dependencies
- [New dependency]: [version]
```

---

## Step 9: Context Compact üóúÔ∏è

**CRITICAL STEP - DO NOT SKIP!**

```
‚òê Phase implementation is 100% complete
‚òê All files committed to git
‚òê User initiates compact: "Let's compact before Phase X+1"
‚òê Claude saves conversation state
‚òê Context compact executes
‚òê New conversation begins with preserved context
```

**What to preserve:**
```
‚úÖ Implementation state (what's done)
‚úÖ Key decisions made
‚úÖ Links to important files
‚úÖ Next phase plan
‚úÖ Outstanding issues/notes
```

**What to discard:**
```
‚ùå Detailed code discussions
‚ùå Debugging sessions
‚ùå Multiple iterations of same code
‚ùå Verbose research discussions
```

**User signal:**
```
User: "Let's compact before Phase 3"
User: "Context compact time"
User: "Ready to compact"
```

---

## Step 10: Mark Phase Complete ‚úÖ

```
‚òê All code implemented and working
‚òê All tests written and passing (15-30 tests)
‚òê All examples created and tested
‚òê All documentation updated
‚òê Context compacted
‚òê Git committed
‚òê Ready to start next phase
```

**Completion message template:**
```
‚úÖ Phase X Complete!

**Implemented:**
- Component 1
- Component 2
- Component 3

**Tests:** [count] new tests ([total] total)
**Files:** [count] implementation, [count] tests, [count] examples
**Documentation:** README_PHASEX.md, CHANGELOG.md updated
**Context:** Compacted

**Next:** Phase [X+1] - [Phase Name]
```

---

## Quality Gates

### Before exiting Step 1 (Plan Mode)
- ‚úÖ All requirements understood
- ‚úÖ All research gaps identified
- ‚úÖ Implementation approach clear
- ‚úÖ Dependencies verified

### Before exiting Step 5 (Code)
- ‚úÖ All files created
- ‚úÖ No print() statements
- ‚úÖ Proper error handling
- ‚úÖ Type hints present
- ‚úÖ Docstrings complete

### Before exiting Step 6 (Tests)
- ‚úÖ 15-30 tests generated
- ‚úÖ Happy path covered
- ‚úÖ Edge cases covered
- ‚úÖ Error cases covered
- ‚úÖ All tests pass

### Before exiting Step 7 (Examples)
- ‚úÖ Copy-paste ready
- ‚úÖ No TODOs/placeholders
- ‚úÖ Examples tested
- ‚úÖ Comments added

### Before exiting Step 9 (Compact)
- ‚úÖ All work committed
- ‚úÖ Documentation updated
- ‚úÖ Tests passing
- ‚úÖ Phase 100% complete

---

## Common Pitfalls

### ‚ùå Skipping plan mode
**Impact:** Missing requirements, rework needed
**Fix:** Always enter plan mode before coding

### ‚ùå Not generating tests
**Impact:** Quality issues, bugs in production
**Fix:** Generate tests proactively after coding

### ‚ùå Skipping context compact
**Impact:** Context overflow, loss of conversation
**Fix:** Compact after EVERY phase

### ‚ùå Leaving TODOs in examples
**Impact:** Examples not usable
**Fix:** Complete all examples fully

### ‚ùå Deferring documentation
**Impact:** Documentation falls behind, never catches up
**Fix:** Update docs during implementation

---

## Success Metrics Per Phase

```
‚úÖ 3-5 implementation files created
‚úÖ 15-30 tests generated proactively
‚úÖ 80%+ code coverage
‚úÖ 2-4 working examples
‚úÖ Phase README created
‚úÖ CHANGELOG updated
‚úÖ Context compacted
‚úÖ Zero rework required
```

---

**Print this checklist and use it for every phase. Following it ensures zero rework and production-ready code.**
